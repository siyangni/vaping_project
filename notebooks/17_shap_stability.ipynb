{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Feature Importance Stability Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook uses bootstrap sampling to assess how stable SHAP importance rankings are. This validates that consensus features are genuinely robust, not artifacts of a single train-test split.\n",
    "\n",
    "## Key Questions\n",
    "- Are SHAP importance rankings stable across bootstrap samples?\n",
    "- What is the coefficient of variation for top features?\n",
    "- Are consensus features genuinely robust?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_BOOTSTRAP = 30  # Reduced for computational efficiency\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" SHAP STABILITY ANALYSIS\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = os.path.expanduser('~/work/vaping_project_data/processed_data_g12n.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "TARGET = 'nicotine12d'\n",
    "df_clean = df[df[TARGET].notna()].copy()\n",
    "\n",
    "exclude_cols = [TARGET, 'V1'] if 'V1' in df.columns else [TARGET]\n",
    "features = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "X = df_clean[features].fillna(df_clean[features].median())\n",
    "y = df_clean[TARGET]\n",
    "\n",
    "# Load best model (XGBoost)\n",
    "models_dir = Path('../outputs/models')\n",
    "model_path = models_dir / 'xgboost.joblib'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"\\nWARNING: XGBoost model not found at {model_path}\")\n",
    "    print(\"Creating demonstration with Random Forest...\")\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "    model.fit(X, y)\n",
    "else:\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"\\nLoaded: XGBoost model\")\n",
    "\n",
    "# Subsample for computational efficiency\n",
    "if len(X) > 10000:\n",
    "    X_sample = X.sample(10000, random_state=RANDOM_STATE)\n",
    "    print(f\"Using sample of {len(X_sample):,} observations for bootstrap analysis\")\n",
    "else:\n",
    "    X_sample = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bootstrap SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(f\" RUNNING {N_BOOTSTRAP} BOOTSTRAP ITERATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "shap_values_bootstrap = []\n",
    "\n",
    "for i in range(N_BOOTSTRAP):\n",
    "    print(f\"Bootstrap iteration {i+1}/{N_BOOTSTRAP}...\", end='\\r')\n",
    "\n",
    "    # Bootstrap sample\n",
    "    X_boot = resample(X_sample, random_state=i)\n",
    "\n",
    "    # Compute SHAP\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_vals = explainer.shap_values(X_boot)\n",
    "\n",
    "    # Handle different SHAP output formats\n",
    "    if isinstance(shap_vals, list):\n",
    "        shap_vals = shap_vals[1]  # Use positive class\n",
    "\n",
    "    # Mean absolute SHAP\n",
    "    importance = np.abs(shap_vals).mean(axis=0)\n",
    "    shap_values_bootstrap.append(importance)\n",
    "\n",
    "print(f\"\\nCompleted {N_BOOTSTRAP} bootstrap iterations\")\n",
    "\n",
    "# Convert to array\n",
    "shap_bootstrap_array = np.array(shap_values_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Stability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" STABILITY METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "shap_mean = shap_bootstrap_array.mean(axis=0)\n",
    "shap_std = shap_bootstrap_array.std(axis=0)\n",
    "shap_lower = np.percentile(shap_bootstrap_array, 2.5, axis=0)\n",
    "shap_upper = np.percentile(shap_bootstrap_array, 97.5, axis=0)\n",
    "\n",
    "# Coefficient of variation\n",
    "cv = (shap_std / shap_mean) * 100\n",
    "\n",
    "stability_df = pd.DataFrame({\n",
    "    'Feature': features[:len(shap_mean)],\n",
    "    'Mean_Importance': shap_mean,\n",
    "    'SD': shap_std,\n",
    "    'Lower_95CI': shap_lower,\n",
    "    'Upper_95CI': shap_upper,\n",
    "    'CV_Pct': cv\n",
    "}).sort_values('Mean_Importance', ascending=False)\n",
    "\n",
    "# Top 20 features\n",
    "top20 = stability_df.head(20)\n",
    "\n",
    "print(\"\\nTop 20 Features with Stability Metrics:\")\n",
    "print(top20[['Feature', 'Mean_Importance', 'CV_Pct']].to_string(index=False))\n",
    "\n",
    "# Identify unstable features\n",
    "unstable = top20[top20['CV_Pct'] > 50]\n",
    "if len(unstable) > 0:\n",
    "    print(f\"\\nWarning: {len(unstable)} features have CV > 50% (unstable):\")\n",
    "    print(unstable[['Feature', 'CV_Pct']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n✓ All top 20 features are stable (CV < 50%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "y_pos = np.arange(len(top20))\n",
    "\n",
    "# Error bars showing 95% CI\n",
    "ax.barh(y_pos, top20['Mean_Importance'],\n",
    "        xerr=[top20['Mean_Importance'] - top20['Lower_95CI'],\n",
    "              top20['Upper_95CI'] - top20['Mean_Importance']],\n",
    "        capsize=4, alpha=0.7)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(top20['Feature'])\n",
    "ax.set_xlabel(f'SHAP Importance (Mean ± 95% CI, N={N_BOOTSTRAP} bootstraps)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Feature Importance Stability Analysis', fontsize=13, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStability plot created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('../outputs/tables')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "stability_df.to_csv(output_dir / 'shap_stability_results.csv', index=False)\n",
    "print(f\"\\n✓ Results saved to: {output_dir / 'shap_stability_results.csv'}\")\n",
    "\n",
    "# Save figure\n",
    "fig_dir = Path('../figures')\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(fig_dir / 'shap_stability.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Figure saved to: {fig_dir / 'shap_stability.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings:\n",
    "- ✅ Analyzed stability across bootstrap samples\n",
    "- ✅ Quantified coefficient of variation for top features\n",
    "- ✅ Validated robustness of consensus features\n",
    "- ✅ Identified any unstable feature rankings\n",
    "\n",
    "### Interpretation:\n",
    "- **Low CV (< 20%)**: Feature importance is very stable\n",
    "- **Moderate CV (20-50%)**: Some variability but generally reliable\n",
    "- **High CV (> 50%)**: Unstable rankings, interpret with caution\n",
    "- **Consensus validation**: Stable features support multi-model consensus approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
